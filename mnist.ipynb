{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Training a Neural Network with MNIST dataset**"
      ],
      "metadata": {
        "id": "7Y7GYjvfWCIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# command to install tensorflow in notebook.\n",
        "# !pip install tensorflow"
      ],
      "metadata": {
        "id": "Cu021t4fWL56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , models"
      ],
      "metadata": {
        "id": "RCLqCRPOWPIE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "TLzlP7eM-QB-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset and split it into train/test data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1765H3I-X_9",
        "outputId": "3a77f180-081a-459a-d948-6c37f690b38e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize pixel values to [0,1]\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "3DzYjmrk-ixU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build keras sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "since mnist dataset has 0-9 handwritten digits, the last layer should be 10\n",
        "not more not less\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FrnZsxQGHlnb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "metadata": {
        "id": "Pji5IszBH0Po"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(x_train, y_train, epochs=50 , validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d310ugUIQ2r",
        "outputId": "cb094cd7-5ead-4ab1-841b-36b64d82782a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.5288 - val_accuracy: 0.9553 - val_loss: 0.1579\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1748 - val_accuracy: 0.9665 - val_loss: 0.1159\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1222 - val_accuracy: 0.9711 - val_loss: 0.0989\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0946 - val_accuracy: 0.9737 - val_loss: 0.0929\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0831 - val_accuracy: 0.9739 - val_loss: 0.0876\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0731 - val_accuracy: 0.9748 - val_loss: 0.0858\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0628 - val_accuracy: 0.9768 - val_loss: 0.0798\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0547 - val_accuracy: 0.9772 - val_loss: 0.0784\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0485 - val_accuracy: 0.9774 - val_loss: 0.0795\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0413 - val_accuracy: 0.9766 - val_loss: 0.0793\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0412 - val_accuracy: 0.9770 - val_loss: 0.0859\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0398 - val_accuracy: 0.9765 - val_loss: 0.0884\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0364 - val_accuracy: 0.9772 - val_loss: 0.0843\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0330 - val_accuracy: 0.9758 - val_loss: 0.0917\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0324 - val_accuracy: 0.9781 - val_loss: 0.0857\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0272 - val_accuracy: 0.9763 - val_loss: 0.0896\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0238 - val_accuracy: 0.9768 - val_loss: 0.0870\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0272 - val_accuracy: 0.9775 - val_loss: 0.0901\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0231 - val_accuracy: 0.9785 - val_loss: 0.0917\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0250 - val_accuracy: 0.9785 - val_loss: 0.0924\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.9779 - val_loss: 0.0963\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0239 - val_accuracy: 0.9765 - val_loss: 0.1007\n",
            "Epoch 23/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0238 - val_accuracy: 0.9772 - val_loss: 0.0991\n",
            "Epoch 24/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0192 - val_accuracy: 0.9763 - val_loss: 0.1080\n",
            "Epoch 25/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0218 - val_accuracy: 0.9784 - val_loss: 0.0991\n",
            "Epoch 26/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0184 - val_accuracy: 0.9772 - val_loss: 0.1034\n",
            "Epoch 27/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0176 - val_accuracy: 0.9776 - val_loss: 0.1015\n",
            "Epoch 28/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0195 - val_accuracy: 0.9778 - val_loss: 0.1016\n",
            "Epoch 29/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0170 - val_accuracy: 0.9772 - val_loss: 0.1087\n",
            "Epoch 30/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0190 - val_accuracy: 0.9785 - val_loss: 0.1046\n",
            "Epoch 31/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0176 - val_accuracy: 0.9774 - val_loss: 0.1125\n",
            "Epoch 32/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0205 - val_accuracy: 0.9771 - val_loss: 0.1092\n",
            "Epoch 33/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0175 - val_accuracy: 0.9787 - val_loss: 0.1079\n",
            "Epoch 34/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0163 - val_accuracy: 0.9761 - val_loss: 0.1177\n",
            "Epoch 35/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0150 - val_accuracy: 0.9780 - val_loss: 0.1083\n",
            "Epoch 36/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0200 - val_accuracy: 0.9765 - val_loss: 0.1154\n",
            "Epoch 37/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0145 - val_accuracy: 0.9781 - val_loss: 0.1165\n",
            "Epoch 38/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.9778 - val_loss: 0.1173\n",
            "Epoch 39/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0137 - val_accuracy: 0.9770 - val_loss: 0.1229\n",
            "Epoch 40/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9781 - val_loss: 0.1225\n",
            "Epoch 41/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0138 - val_accuracy: 0.9787 - val_loss: 0.1207\n",
            "Epoch 42/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0138 - val_accuracy: 0.9797 - val_loss: 0.1165\n",
            "Epoch 43/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0141 - val_accuracy: 0.9793 - val_loss: 0.1232\n",
            "Epoch 44/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9775 - val_loss: 0.1190\n",
            "Epoch 45/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.9781 - val_loss: 0.1211\n",
            "Epoch 46/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0165 - val_accuracy: 0.9786 - val_loss: 0.1185\n",
            "Epoch 47/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0135 - val_accuracy: 0.9791 - val_loss: 0.1202\n",
            "Epoch 48/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9801 - val_loss: 0.1164\n",
            "Epoch 49/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0127 - val_accuracy: 0.9789 - val_loss: 0.1249\n",
            "Epoch 50/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0126 - val_accuracy: 0.9793 - val_loss: 0.1284\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787238a590f0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "test_loss , test_acc = model.evaluate(x_test , y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiJCOOsKItZw",
        "outputId": "2e59b35a-9545-4d62-e8c4-c2ec75059d8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.1379\n",
            "Test Accuracy: 0.9797999858856201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "index = 0\n",
        "predictions = model.predict(x_test)\n",
        "predicted_class = tf.argmax(predictions[index]).numpy()\n",
        "print(f\"Predicted number on the image: {predicted_class}\")\n",
        "\n",
        "# check what is the image which is to be predicted.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test[index], cmap='gray')\n",
        "plt.axis('off')  # Hide the axes\n",
        "print(\"Image:\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "F5hcnGZtI1Bv",
        "outputId": "9a1820ef-7260-4691-ac76-0527bdfc556d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Predicted number on the image: 7\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPu1ZtFL9POG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}